{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ddec263",
   "metadata": {},
   "source": [
    "# Cross-Species Consensus Peak Pipeline\n",
    "\n",
    "This notebook creates a unified peak set across species for cross-species accessibility comparison.\n",
    "\n",
    "**Pipeline steps:**\n",
    "1. Liftover species consensus peaks ‚Üí hg38 (human)\n",
    "2. Merge all lifted peaks into unified human consensus\n",
    "3. Add peak IDs for tracking across species\n",
    "4. Liftover unified peaks back to each species genome\n",
    "5. Create presence/absence matrix\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b4c7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "PIPELINE_DIR = Path(os.getcwd()).parent if 'notebooks' in os.getcwd() else Path(os.getcwd())\n",
    "sys.path.insert(0, str(PIPELINE_DIR))\n",
    "\n",
    "from src import (\n",
    "    cross_species_consensus_pipeline,\n",
    "    create_peak_matrix,\n",
    "    liftover_two_step,\n",
    "    get_chain_file,\n",
    "    DEFAULT_CHAIN_DIR,\n",
    "    REVERSE_CHAIN_FILES,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Pipeline loaded from {PIPELINE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4497bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show available reverse chain files (for lifting back)\n",
    "print(\"Available reverse chain files (hg38 ‚Üí species):\")\n",
    "print(\"=\" * 50)\n",
    "for species, chain in REVERSE_CHAIN_FILES.items():\n",
    "    chain_path = os.path.join(DEFAULT_CHAIN_DIR, chain)\n",
    "    exists = \"‚úÖ\" if os.path.exists(chain_path) else \"‚ùå\"\n",
    "    print(f\"{exists} {species}: {chain}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c61b36b",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your input files and output directory below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Edit these paths\n",
    "# =============================================================================\n",
    "\n",
    "# Input consensus BED files (species-specific coordinates)\n",
    "SPECIES_BEDS = {\n",
    "    \"Gorilla\": \"/path/to/Gorilla_consensus_peaks.bed\",\n",
    "    \"Chimpanzee\": \"/path/to/Chimpanzee_consensus_peaks.bed\",\n",
    "    \"Bonobo\": \"/path/to/Bonobo_consensus_peaks.bed\",\n",
    "    \"Macaque\": \"/path/to/Macaque_consensus_peaks.bed\",\n",
    "    \"Marmoset\": \"/path/to/Marmoset_consensus_peaks.bed\",\n",
    "}\n",
    "\n",
    "# Output directory for all results\n",
    "OUTPUT_DIR = \"/path/to/output/cross_species_consensus\"\n",
    "\n",
    "# Chain file directory\n",
    "CHAIN_DIR = DEFAULT_CHAIN_DIR\n",
    "\n",
    "# liftOver executable path (on cluster)\n",
    "LIFTOVER_PATH = \"/cluster/project/treutlein/jjans/software/miniforge3/envs/genomes/bin/liftOver\"\n",
    "\n",
    "# Peak ID prefix\n",
    "PEAK_PREFIX = \"unified\"\n",
    "\n",
    "# Merge distance (0 = only overlapping peaks merge)\n",
    "MERGE_DISTANCE = 0\n",
    "\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e81ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate input files\n",
    "print(\"Input files:\")\n",
    "print(\"=\" * 60)\n",
    "for species, filepath in SPECIES_BEDS.items():\n",
    "    exists = os.path.exists(filepath)\n",
    "    if exists:\n",
    "        # Count peaks\n",
    "        with open(filepath) as f:\n",
    "            n_peaks = sum(1 for line in f if line.strip() and not line.startswith('#'))\n",
    "        print(f\"‚úÖ {species}: {n_peaks:,} peaks\")\n",
    "    else:\n",
    "        print(f\"‚ùå {species}: NOT FOUND - {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29fa833",
   "metadata": {},
   "source": [
    "## Run Full Pipeline\n",
    "\n",
    "This runs the complete cross-species consensus pipeline in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce304319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full pipeline\n",
    "results = cross_species_consensus_pipeline(\n",
    "    species_beds=SPECIES_BEDS,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    chain_dir=CHAIN_DIR,\n",
    "    liftover_path=LIFTOVER_PATH,\n",
    "    min_match=0.95,\n",
    "    merge_distance=MERGE_DISTANCE,\n",
    "    peak_prefix=PEAK_PREFIX,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(f\"\\n{results['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb2faa3",
   "metadata": {},
   "source": [
    "## Create Peak Presence Matrix\n",
    "\n",
    "Creates a matrix showing which peaks are present/absent in each species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create peak presence/absence matrix\n",
    "if results[\"status\"] == \"success\":\n",
    "    matrix_file = os.path.join(OUTPUT_DIR, \"peak_presence_matrix.tsv\")\n",
    "    \n",
    "    # Get the lifted-back BED files\n",
    "    species_lifted_beds = {\n",
    "        species: results[\"output_files\"][species]\n",
    "        for species in SPECIES_BEDS.keys()\n",
    "        if species in results[\"output_files\"]\n",
    "    }\n",
    "    \n",
    "    matrix_result = create_peak_matrix(\n",
    "        unified_human_bed=results[\"output_files\"][\"human_consensus\"],\n",
    "        species_beds=species_lifted_beds,\n",
    "        output_file=matrix_file,\n",
    "        verbose=True,\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Pipeline did not complete successfully, skipping matrix creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bfbee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the matrix\n",
    "if results[\"status\"] == \"success\":\n",
    "    import pandas as pd\n",
    "    \n",
    "    matrix_df = pd.read_csv(matrix_file, sep='\\t')\n",
    "    print(f\"Matrix shape: {matrix_df.shape}\")\n",
    "    print(f\"\\nFirst 10 rows:\")\n",
    "    display(matrix_df.head(10))\n",
    "    \n",
    "    # Summary statistics\n",
    "    species_cols = [col for col in matrix_df.columns if col not in ['peak_id', 'chr', 'start', 'end']]\n",
    "    print(f\"\\nüìä Peaks per species:\")\n",
    "    for sp in species_cols:\n",
    "        count = matrix_df[sp].sum()\n",
    "        pct = count / len(matrix_df) * 100\n",
    "        print(f\"   {sp}: {count:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d1a8b8",
   "metadata": {},
   "source": [
    "## Conservation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50861156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze conservation levels\n",
    "if results[\"status\"] == \"success\":\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    matrix_df = pd.read_csv(matrix_file, sep='\\t')\n",
    "    species_cols = [col for col in matrix_df.columns if col not in ['peak_id', 'chr', 'start', 'end']]\n",
    "    \n",
    "    # Calculate how many species each peak is present in\n",
    "    matrix_df['n_species'] = matrix_df[species_cols].sum(axis=1)\n",
    "    \n",
    "    # Count distribution\n",
    "    conservation_counts = matrix_df['n_species'].value_counts().sort_index()\n",
    "    \n",
    "    print(\"üìä Peak conservation distribution:\")\n",
    "    print(\"=\" * 40)\n",
    "    for n, count in conservation_counts.items():\n",
    "        pct = count / len(matrix_df) * 100\n",
    "        bar = \"‚ñà\" * int(pct / 2)\n",
    "        print(f\"{n} species: {count:>6,} ({pct:>5.1f}%) {bar}\")\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    conservation_counts.plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')\n",
    "    ax.set_xlabel('Number of species with peak')\n",
    "    ax.set_ylabel('Number of peaks')\n",
    "    ax.set_title('Peak Conservation Across Species')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_file = os.path.join(OUTPUT_DIR, \"conservation_distribution.png\")\n",
    "    plt.savefig(plot_file, dpi=150)\n",
    "    print(f\"\\nüìä Plot saved: {plot_file}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a7654",
   "metadata": {},
   "source": [
    "## Output Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d39fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all output files\n",
    "print(\"\\nüìÅ Output files:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for root, dirs, files in os.walk(OUTPUT_DIR):\n",
    "    level = root.replace(OUTPUT_DIR, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        filepath = os.path.join(root, file)\n",
    "        size_kb = os.path.getsize(filepath) / 1024\n",
    "        print(f\"{subindent}{file} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d266f59",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Manual Step-by-Step (Alternative)\n",
    "\n",
    "If you prefer more control, you can run each step individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # STEP 1: Liftover to human (uncomment to run manually)\n",
    "# from src import liftover_peaks, liftover_two_step, get_chain_file\n",
    "# \n",
    "# lifted_beds = []\n",
    "# for species, input_bed in SPECIES_BEDS.items():\n",
    "#     output_bed = f\"{OUTPUT_DIR}/01_lifted_to_human/{species}_hg38.bed\"\n",
    "#     os.makedirs(os.path.dirname(output_bed), exist_ok=True)\n",
    "#     \n",
    "#     if species == \"Marmoset\":\n",
    "#         result = liftover_two_step(\n",
    "#             input_bed=input_bed,\n",
    "#             output_bed=output_bed,\n",
    "#             chain_file_1=get_chain_file(\"Marmoset_step1\"),\n",
    "#             chain_file_2=get_chain_file(\"Marmoset_step2\"),\n",
    "#             liftover_path=LIFTOVER_PATH,\n",
    "#         )\n",
    "#     else:\n",
    "#         result = liftover_peaks(\n",
    "#             input_bed=input_bed,\n",
    "#             output_bed=output_bed,\n",
    "#             chain_file=get_chain_file(species),\n",
    "#             liftover_path=LIFTOVER_PATH,\n",
    "#         )\n",
    "#     \n",
    "#     if result[\"status\"] == \"success\":\n",
    "#         lifted_beds.append(output_bed)\n",
    "#     print(result[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876e8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # STEP 2: Merge peaks (uncomment to run manually)\n",
    "# from src import merge_bed_files, add_peak_ids\n",
    "# \n",
    "# merged_bed = f\"{OUTPUT_DIR}/02_merged_consensus/unified_consensus_hg38.bed\"\n",
    "# merge_bed_files(lifted_beds, merged_bed, merge_distance=0)\n",
    "# \n",
    "# # Add IDs\n",
    "# merged_with_ids = merged_bed.replace('.bed', '_with_ids.bed')\n",
    "# add_peak_ids(merged_bed, merged_with_ids, prefix=\"unified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # STEP 3: Liftback to species (uncomment to run manually)\n",
    "# from src import liftback_peaks\n",
    "# \n",
    "# for species in SPECIES_BEDS.keys():\n",
    "#     output_bed = f\"{OUTPUT_DIR}/03_lifted_back/unified_consensus_{species}.bed\"\n",
    "#     os.makedirs(os.path.dirname(output_bed), exist_ok=True)\n",
    "#     \n",
    "#     result = liftback_peaks(\n",
    "#         input_bed=merged_with_ids,\n",
    "#         output_bed=output_bed,\n",
    "#         species=species,\n",
    "#         chain_dir=CHAIN_DIR,\n",
    "#         liftover_path=LIFTOVER_PATH,\n",
    "#     )\n",
    "#     print(result[\"message\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
