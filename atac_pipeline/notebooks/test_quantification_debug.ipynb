{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48fa838",
   "metadata": {},
   "source": [
    "# Debug: Quantification returning zeros\n",
    "\n",
    "Test with Bonobo Adipocytes fragments and liftback peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93f0bfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedtools v2.31.1\n"
     ]
    }
   ],
   "source": [
    "import os, sys, gzip, subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add bedtools to PATH (lives in scenicplus conda env)\n",
    "bedtools_dir = '/cluster/project/treutlein/jjans/software/miniforge3/envs/scenicplus/bin'\n",
    "os.environ['PATH'] = bedtools_dir + ':' + os.environ.get('PATH', '')\n",
    "\n",
    "sys.path.insert(0, '/cluster/home/jjanssens/jjans/analysis/adult_intestine/peaks/peak_calling/atac_pipeline')\n",
    "\n",
    "FRAG_FILE = '/cluster/project/treutlein/USERS/jjans/analysis/adult_intestine/peaks/fragment_files/Bonobo/Adipocytes.fragments.tsv.gz'\n",
    "PEAK_FILE = '/cluster/project/treutlein/USERS/jjans/analysis/adult_intestine/peaks/cross_species_consensus/03_lifted_back/unified_consensus_Bonobo.bed'\n",
    "\n",
    "# Verify bedtools\n",
    "result = subprocess.run('bedtools --version', shell=True, capture_output=True, text=True)\n",
    "print(result.stdout.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b6a682a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FRAGMENT FILE ===\n",
      "'1\\t769687\\t769688\\t.\\t.\\t+'\n",
      "'1\\t769724\\t769725\\t.\\t.\\t-'\n",
      "'1\\t770624\\t770625\\t.\\t.\\t+'\n",
      "'1\\t770669\\t770670\\t.\\t.\\t-'\n",
      "'1\\t773197\\t773198\\t.\\t.\\t+'\n",
      "'1\\t773356\\t773357\\t.\\t.\\t-'\n",
      "'1\\t776675\\t776676\\t.\\t.\\t+'\n",
      "'1\\t776733\\t776734\\t.\\t.\\t-'\n",
      "'1\\t777827\\t777828\\t.\\t.\\t+'\n",
      "'1\\t778048\\t778049\\t.\\t.\\t-'\n",
      "'1\\t778530\\t778531\\t.\\t.\\t+'\n",
      "'1\\t778900\\t778901\\t.\\t.\\t-'\n",
      "'1\\t778962\\t778963\\t.\\t.\\t+'\n",
      "'1\\t779139\\t779140\\t.\\t.\\t-'\n",
      "'1\\t779293\\t779294\\t.\\t.\\t+'\n",
      "'1\\t779389\\t779390\\t.\\t.\\t-'\n",
      "'1\\t779925\\t779926\\t.\\t.\\t+'\n",
      "'1\\t780054\\t780055\\t.\\t.\\t-'\n",
      "'1\\t785799\\t785800\\t.\\t.\\t+'\n",
      "'1\\t785965\\t785966\\t.\\t.\\t-'\n"
     ]
    }
   ],
   "source": [
    "# 1. Inspect fragment file: first 20 lines\n",
    "print('=== FRAGMENT FILE ===')\n",
    "with gzip.open(FRAG_FILE, 'rt') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 20:\n",
    "            break\n",
    "        print(repr(line.rstrip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "459c95e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fragment lengths (first 10000 entries):\n",
      "   min: 1, max: 1, median: 1.0\n",
      "   unique values: [1]\n",
      "   all length==1: True\n",
      "\n",
      "These fragments are ALREADY cut-sites\n"
     ]
    }
   ],
   "source": [
    "# 2. Check if fragments are already cut-sites (length == 1)\n",
    "lengths = []\n",
    "with gzip.open(FRAG_FILE, 'rt') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 10000:\n",
    "            break\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) >= 3 and not line.startswith('#'):\n",
    "            lengths.append(int(parts[2]) - int(parts[1]))\n",
    "\n",
    "lengths = np.array(lengths)\n",
    "print(f'Fragment lengths (first {len(lengths)} entries):')\n",
    "print(f'   min: {lengths.min()}, max: {lengths.max()}, median: {np.median(lengths)}')\n",
    "print(f'   unique values: {np.unique(lengths)}')\n",
    "print(f'   all length==1: {(lengths == 1).all()}')\n",
    "print(f'\\nThese fragments are {\"ALREADY cut-sites\" if (lengths == 1).all() else \"paired-end fragments\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42da3800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PEAK FILE ===\n",
      "'chr4\\t168323332\\t168323405\\tunified_000003\\tchr1:136132-136205'\n",
      "'chr12\\t55039\\t57560\\tunified_000008\\tchr1:191241-191741'\n",
      "'chr4\\t168307953\\t168308072\\tunified_000009\\tchr1:288851-288970'\n",
      "'chr17\\t83431310\\t83431810\\tunified_000012\\tchr1:593175-593675'\n",
      "'chrM\\t3946\\t4446\\tunified_000014\\tchr1:629696-630196'\n",
      "'chrM\\t4669\\t4869\\tunified_000015\\tchr1:630419-630619'\n",
      "'chrM\\t8024\\t8524\\tunified_000016\\tchr1:633774-634274'\n",
      "'chr7\\t56713159\\t56713654\\tunified_000017\\tchr1:732235-732735'\n",
      "'chr7\\t82525154\\t82525323\\tunified_000018\\tchr1:737317-737486'\n",
      "'chr11\\t50206302\\t50206800\\tunified_000019\\tchr1:770343-770813'\n"
     ]
    }
   ],
   "source": [
    "# 3. Inspect peak file: first 10 lines\n",
    "print('=== PEAK FILE ===')\n",
    "with open(PEAK_FILE) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 10:\n",
    "            break\n",
    "        print(repr(line.rstrip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc9e9c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fragment chroms (sample): ['1']\n",
      "Peak chroms (sample):     ['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18']\n",
      "\n",
      "Fragment has chr prefix: False\n",
      "Peak has chr prefix:     True\n",
      "\n",
      "Overlapping chroms: 0\n",
      ">>> NO OVERLAP - this is why you get zeros! <<<\n"
     ]
    }
   ],
   "source": [
    "# 4. Compare chromosome naming conventions\n",
    "frag_chroms = set()\n",
    "with gzip.open(FRAG_FILE, 'rt') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 10000:\n",
    "            break\n",
    "        parts = line.strip().split('\\t')\n",
    "        if parts and not line.startswith('#'):\n",
    "            frag_chroms.add(parts[0])\n",
    "\n",
    "# Peak file has 5 columns (chr, start, end, name, hg38_coords)\n",
    "peak_df = pd.read_csv(PEAK_FILE, sep='\\t', header=None, usecols=[0,1,2,3],\n",
    "                       names=['Chromosome','Start','End','Name'], dtype={'Chromosome': str})\n",
    "peak_chroms = set(peak_df['Chromosome'].unique())\n",
    "\n",
    "print(f'Fragment chroms (sample): {sorted(frag_chroms)[:10]}')\n",
    "print(f'Peak chroms (sample):     {sorted(peak_chroms)[:10]}')\n",
    "print(f'\\nFragment has chr prefix: {any(c.startswith(\"chr\") for c in frag_chroms)}')\n",
    "print(f'Peak has chr prefix:     {any(c.startswith(\"chr\") for c in peak_chroms)}')\n",
    "\n",
    "overlap = frag_chroms & peak_chroms\n",
    "print(f'\\nOverlapping chroms: {len(overlap)}')\n",
    "if not overlap:\n",
    "    print('>>> NO OVERLAP - this is why you get zeros! <<<')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aaf5819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fragment file has 6 columns\n",
      "Line: '1\\t769687\\t769688\\t.\\t.\\t+'\n",
      "\n",
      "Format: chr start end barcode score (standard fragments)\n"
     ]
    }
   ],
   "source": [
    "# 5. Check column count in fragments (is there a barcode / score column?)\n",
    "with gzip.open(FRAG_FILE, 'rt') as f:\n",
    "    line = next(f)\n",
    "    n_cols = len(line.strip().split('\\t'))\n",
    "    print(f'Fragment file has {n_cols} columns')\n",
    "    print(f'Line: {repr(line.rstrip())}')\n",
    "    print()\n",
    "    if n_cols == 3:\n",
    "        print('Format: chr start end  (pure BED3 - cut-sites only, no barcode)')\n",
    "    elif n_cols == 4:\n",
    "        print('Format: chr start end barcode')\n",
    "    elif n_cols >= 5:\n",
    "        print('Format: chr start end barcode score (standard fragments)')\n",
    "    elif n_cols == 6:\n",
    "        print('Format: chr start end name score strand (BED6 - cut-sites with strand)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6990c34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing: removing chr prefix from peaks\n",
      "Peak chroms after fix: ['1', '11', '12', '17', '4']\n",
      "\n",
      "=== bedtools intersect -c (coverage count) ===\n",
      "4\t168323332\t168323405\tunified_000003\t1\n",
      "12\t55039\t57560\tunified_000008\t0\n",
      "4\t168307953\t168308072\tunified_000009\t0\n",
      "17\t83431310\t83431810\tunified_000012\t0\n",
      "M\t3946\t4446\tunified_000014\t0\n",
      "M\t4669\t4869\tunified_000015\t0\n",
      "M\t8024\t8524\tunified_000016\t0\n",
      "7\t56713159\t56713654\tunified_000017\t0\n",
      "7\t82525154\t82525323\tunified_000018\t1\n",
      "11\t50206302\t50206800\tunified_000019\t0\n",
      "7\t57159132\t57159977\tunified_000021\t10\n",
      "7\t56768877\t56769376\tunified_000022\t2\n",
      "7\t56771831\t56772314\tunified_000024\t1\n",
      "7\t56774392\t56774900\tunified_000027\t0\n",
      "8\t348563\t349063\tunified_000028\t0\n",
      "8\t347935\t348429\tunified_000029\t0\n",
      "Un_NW_014017077v1\t25235\t26084\tunified_000033\t0\n",
      "Un_NW_014017077v1\t26185\t26797\tunified_000034\t0\n",
      "Un_NW_014024175v1\t23620\t24120\tunified_000039\t0\n",
      "Un_NW_014024175v1\t22938\t23553\tunified_000040\t0\n",
      "\n",
      "Total peaks tested: 5000\n",
      "Non-zero: 1722\n",
      "Sum: 5291\n",
      "Max: 30\n"
     ]
    }
   ],
   "source": [
    "# 6. Direct bedtools test with a small subset\n",
    "# Subset peaks to first 5000\n",
    "peaks_subset = peak_df.head(5000).copy()\n",
    "\n",
    "# If chr mismatch, fix it for this test\n",
    "frag_has_chr = any(c.startswith('chr') for c in frag_chroms)\n",
    "peak_has_chr = any(c.startswith('chr') for c in peak_chroms)\n",
    "\n",
    "if frag_has_chr and not peak_has_chr:\n",
    "    print('Fixing: adding chr prefix to peaks')\n",
    "    peaks_subset['Chromosome'] = 'chr' + peaks_subset['Chromosome'].astype(str)\n",
    "elif not frag_has_chr and peak_has_chr:\n",
    "    print('Fixing: removing chr prefix from peaks')\n",
    "    peaks_subset['Chromosome'] = peaks_subset['Chromosome'].astype(str).str.replace(r'^chr', '', regex=True)\n",
    "else:\n",
    "    print('Chr naming already matches')\n",
    "\n",
    "print(f'Peak chroms after fix: {sorted(peaks_subset[\"Chromosome\"].unique())[:5]}')\n",
    "\n",
    "# Write temp peaks\n",
    "import tempfile\n",
    "tmp_peaks = tempfile.mktemp(suffix='.bed')\n",
    "peaks_subset[['Chromosome','Start','End','Name']].to_csv(tmp_peaks, sep='\\t', header=False, index=False)\n",
    "\n",
    "# Test: simple coverage count (fragments overlapping peaks)\n",
    "cmd = f'bedtools intersect -a {tmp_peaks} -b {FRAG_FILE} -c | head -20'\n",
    "print(f'\\n=== bedtools intersect -c (coverage count) ===')\n",
    "result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(f'STDERR: {result.stderr}')\n",
    "\n",
    "# Count non-zero\n",
    "cmd_all = f'bedtools intersect -a {tmp_peaks} -b {FRAG_FILE} -c'\n",
    "result_all = subprocess.run(cmd_all, shell=True, capture_output=True, text=True)\n",
    "counts = [int(line.split('\\t')[-1]) for line in result_all.stdout.strip().split('\\n') if line]\n",
    "counts = np.array(counts)\n",
    "print(f'Total peaks tested: {len(counts)}')\n",
    "print(f'Non-zero: {(counts > 0).sum()}')\n",
    "print(f'Sum: {counts.sum()}')\n",
    "print(f'Max: {counts.max()}')\n",
    "\n",
    "os.unlink(tmp_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1467895e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Quantifying Adipocytes.fragments.tsv.gz (fragments) over 840,026 peaks...\n",
      "  Auto-detected 1bp cut-site fragments, using 'coverage' instead of 'cutsites'\n",
      "\n",
      "method=cutsites (auto-detected): non-zero = 258726 / 840026\n",
      "Sum: 719972\n",
      "unified_000003     1\n",
      "unified_000018     1\n",
      "unified_000021    10\n",
      "unified_000022     2\n",
      "unified_000024     1\n",
      "unified_000050     2\n",
      "unified_000051     2\n",
      "unified_000052     2\n",
      "unified_000054     3\n",
      "unified_000069     1\n",
      "Name: Adipocytes.fragments.tsv, dtype: int64\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š Quantifying Adipocytes.fragments.tsv.gz (fragments) over 840,026 peaks...\n",
      "\n",
      "method=coverage: non-zero = 258726 / 840026\n",
      "Sum: 719972\n",
      "unified_000003     1\n",
      "unified_000018     1\n",
      "unified_000021    10\n",
      "unified_000022     2\n",
      "unified_000024     1\n",
      "unified_000050     2\n",
      "unified_000051     2\n",
      "unified_000052     2\n",
      "unified_000054     3\n",
      "unified_000069     1\n",
      "Name: Adipocytes.fragments.tsv, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 7. Test the quantify function with the FIXED code\n",
    "# Reload the module to pick up changes\n",
    "import importlib\n",
    "import src.quantification\n",
    "importlib.reload(src.quantification)\n",
    "from src.quantification import quantify\n",
    "\n",
    "# Since fragments are already cut-sites, the auto-detect should kick in\n",
    "# even when method='cutsites' is passed\n",
    "result_cutsites = quantify(\n",
    "    input_file=FRAG_FILE,\n",
    "    peak_file=PEAK_FILE,\n",
    "    input_type='fragments',\n",
    "    method='cutsites',\n",
    "    verbose=True,\n",
    ")\n",
    "print(f'\\nmethod=cutsites (auto-detected): non-zero = {(result_cutsites > 0).sum()} / {len(result_cutsites)}')\n",
    "print(f'Sum: {result_cutsites.sum()}')\n",
    "print(result_cutsites[result_cutsites > 0].head(10))\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "\n",
    "# Also test explicit coverage\n",
    "result_coverage = quantify(\n",
    "    input_file=FRAG_FILE,\n",
    "    peak_file=PEAK_FILE,\n",
    "    input_type='fragments',\n",
    "    method='coverage',\n",
    "    verbose=True,\n",
    ")\n",
    "print(f'\\nmethod=coverage: non-zero = {(result_coverage > 0).sum()} / {len(result_coverage)}')\n",
    "print(f'Sum: {result_coverage.sum()}')\n",
    "print(result_coverage[result_coverage > 0].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56f354d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are fragments already cut-sites? True\n",
      "\n",
      "Peaks before harmonize: ['chr1', 'chr11', 'chr12', 'chr17', 'chr4']\n",
      "Detected input chroms:  ['1']\n",
      "Peaks after harmonize:  ['1', '11', '12', '17', '4']\n",
      "Was modified: True\n"
     ]
    }
   ],
   "source": [
    "# 8. Test auto-detection function directly\n",
    "importlib.reload(src.quantification)\n",
    "from src.quantification import _are_fragments_already_cutsites, _detect_input_chroms, _harmonize_chr_prefix\n",
    "from src.utils import load_peaks\n",
    "\n",
    "is_cutsites = _are_fragments_already_cutsites(FRAG_FILE)\n",
    "print(f'Are fragments already cut-sites? {is_cutsites}')\n",
    "\n",
    "# Test chr harmonization\n",
    "peaks_orig = load_peaks(PEAK_FILE).head(5000)\n",
    "print(f'\\nPeaks before harmonize: {sorted(peaks_orig[\"Chromosome\"].unique())[:5]}')\n",
    "\n",
    "detected = _detect_input_chroms(FRAG_FILE, 'fragments')\n",
    "print(f'Detected input chroms:  {sorted(detected)[:5]}')\n",
    "\n",
    "peaks_fixed = _harmonize_chr_prefix(peaks_orig, FRAG_FILE, 'fragments')\n",
    "print(f'Peaks after harmonize:  {sorted(peaks_fixed[\"Chromosome\"].unique())[:5]}')\n",
    "print(f'Was modified: {not peaks_orig[\"Chromosome\"].equals(peaks_fixed[\"Chromosome\"])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
