{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4867f9b1-8d44-43f7-bf85-1920097d9076",
   "metadata": {},
   "source": [
    "# ATAC-seq Peak Calling Pipeline\n",
    "\n",
    "This notebook provides a complete pipeline for ATAC-seq peak calling:\n",
    "\n",
    "1. **Step 1**: Convert fragment files to Tn5 cut-site BED files\n",
    "2. **Step 2**: Run MACS3 peak calling on the cut-site files\n",
    "\n",
    "## Overview\n",
    "\n",
    "For ATAC-seq data, each fragment represents DNA between two Tn5 transposase insertion sites. This pipeline:\n",
    "- Extracts the cut sites (both ends of each fragment)\n",
    "- Calls peaks using MACS3 with ATAC-seq optimized parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a6ebcc-c6ec-4297-b50b-afc521e46ea8",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set all parameters here before running the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ccd1ee-2601-4828-98f2-0a00ce825ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species: Macaque\n",
      "Genome size: 2,653,677,440\n",
      "Cut-sites output: /cluster/project/treutlein/USERS/jjans/analysis/adult_intestine/peaks/fragment_files/Macaque\n",
      "Peaks output: /cluster/project/treutlein/USERS/jjans/analysis/adult_intestine/peaks/consensus_peak_calling_Macaque\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "from functools import partial\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION - Modify these parameters as needed\n",
    "# =============================================================================\n",
    "\n",
    "# Species selection\n",
    "SPECIES = \"Macaque\"  # Options: Human, Bonobo, Macaque, Chimpanzee, Gorilla, Marmoset\n",
    "\n",
    "# Effective genome sizes for each species\n",
    "EFFECTIVE_GENOME_SIZES = {\n",
    "    'Bonobo': 2595269547,\n",
    "    'Macaque': 2653677440,\n",
    "    'Chimpanzee': 2792339170,\n",
    "    'Gorilla': 2661668758,\n",
    "    'Marmoset': 2597026658,\n",
    "    'Human': 2913022398  # value from macs3 site (deeptools)\n",
    "}\n",
    "\n",
    "# Directory paths\n",
    "BASE_DIR = \"/cluster/home/jjanssens/jjans/analysis/adult_intestine/peaks\"\n",
    "FRAGMENTS_INPUT_DIR = f\"../atac/consensus_peak_calling_{SPECIES}_filter/pseudobulk_bed_files/\"\n",
    "CUTSITES_OUTPUT_DIR = os.path.join(os.getcwd(), f\"fragment_files/{SPECIES}\")\n",
    "PEAKS_OUTPUT_DIR = os.path.join(os.getcwd(), f\"consensus_peak_calling_{SPECIES}\")\n",
    "\n",
    "# MACS3 executable path\n",
    "MACS3_PATH = \"/cluster/project/treutlein/jjans/software/miniforge3/envs/scenicplus/bin/macs3\"\n",
    "\n",
    "# Parallel processing\n",
    "CUTSITE_WORKERS = 8   # Workers for fragment conversion (I/O bound)\n",
    "MACS3_WORKERS = 15    # Workers for MACS3 peak calling (CPU bound)\n",
    "\n",
    "print(f\"Species: {SPECIES}\")\n",
    "print(f\"Genome size: {EFFECTIVE_GENOME_SIZES[SPECIES]:,}\")\n",
    "print(f\"Cut-sites output: {CUTSITES_OUTPUT_DIR}\")\n",
    "print(f\"Peaks output: {PEAKS_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b0878-87c7-48f7-a22a-d4938b80e68f",
   "metadata": {},
   "source": [
    "## MACS3 Parameters\n",
    "\n",
    "Configure MACS3 peak calling parameters. These are optimized for ATAC-seq data.\n",
    "\n",
    "Documentation: https://github.com/macs3-project/MACS/blob/master/docs/callpeak.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def2179e-1583-4d2f-b2ea-40b1e88bb7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACS3 Parameters:\n",
      "  format: BED\n",
      "  qvalue: 0.01\n",
      "  shift: -73\n",
      "  extsize: 146\n",
      "  keep_dup: all\n",
      "  min_length: 200\n",
      "  nomodel: True\n",
      "  call_summits: True\n",
      "  nolambda: True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MACS3 PARAMETERS\n",
    "# =============================================================================\n",
    "\n",
    "MACS3_PARAMS = {\n",
    "    # Input format: BED, BAM, SAM, BEDPE, etc.\n",
    "    \"format\": \"BED\",\n",
    "    \n",
    "    # q-value (minimum FDR) cutoff for peak detection\n",
    "    \"qvalue\": 0.01,\n",
    "    \n",
    "    # Shift reads by this amount (negative for ATAC-seq to center on cut site)\n",
    "    \"shift\": -73,\n",
    "    \n",
    "    # Extend reads to this fragment size\n",
    "    \"extsize\": 146,\n",
    "    \n",
    "    # How to handle duplicate reads: \"auto\", \"all\", or integer\n",
    "    \"keep_dup\": \"all\",\n",
    "    \n",
    "    # Minimum length of peak region\n",
    "    \"min_length\": 200,\n",
    "    \n",
    "    # Boolean flags\n",
    "    \"nomodel\": True,       # Skip model building, use shift/extsize directly\n",
    "    \"call_summits\": True,  # Call peak summits (required for narrowPeak output)\n",
    "    \"nolambda\": True,      # Use fixed background lambda\n",
    "}\n",
    "\n",
    "print(\"MACS3 Parameters:\")\n",
    "for key, value in MACS3_PARAMS.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e03506-b3c1-4cf9-91ae-6083aea8660e",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 1: Convert Fragments to Cut-Sites\n",
    "\n",
    "Convert paired-end fragment files to single-nucleotide Tn5 cut-site BED files.\n",
    "\n",
    "For each fragment (chr, start, end), we extract:\n",
    "- **5' cut site**: (chr, start, start+1) with + strand\n",
    "- **3' cut site**: (chr, end-1, end) with - strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbab71db-d03a-4255-bbbf-136f9e7da1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined for fragment conversion.\n"
     ]
    }
   ],
   "source": [
    "def convert_fragments_to_cutsites(input_fragments: str, output_bed: str) -> dict:\n",
    "    \"\"\"\n",
    "    Convert a paired-end fragments file into a BED file of Tn5 cut sites.\n",
    "    \n",
    "    For ATAC-seq, each fragment has two Tn5 insertion sites:\n",
    "    - 5' end (start position) ‚Üí + strand\n",
    "    - 3' end (end position - 1) ‚Üí - strand\n",
    "    \n",
    "    Input format:  chr  start  end  [barcode]  [count]\n",
    "    Output format: BED6 (chr, start, end, name, score, strand)\n",
    "    \"\"\"\n",
    "    sample_name = Path(input_fragments).name.split('.')[0]\n",
    "    \n",
    "    # awk command to extract both cut sites per fragment\n",
    "    awk_cmd = r\"\"\"awk -v OFS='\\t' '{\n",
    "        print $1, $2, $2+1, \".\", \".\", \"+\";\n",
    "        print $1, $3-1, $3, \".\", \".\", \"-\"\n",
    "    }'\"\"\"\n",
    "    \n",
    "    cmd = f\"zcat {input_fragments} | {awk_cmd} | gzip > {output_bed}\"\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(\n",
    "            cmd, \n",
    "            shell=True, \n",
    "            check=True, \n",
    "            executable='/bin/bash',\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        output_size = os.path.getsize(output_bed) / (1024 * 1024)  # MB\n",
    "        \n",
    "        return {\n",
    "            \"sample\": sample_name,\n",
    "            \"status\": \"success\",\n",
    "            \"output_size_mb\": round(output_size, 2),\n",
    "            \"message\": f\"‚úÖ {sample_name}: {output_size:.1f} MB\"\n",
    "        }\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return {\n",
    "            \"sample\": sample_name,\n",
    "            \"status\": \"error\",\n",
    "            \"output_size_mb\": 0,\n",
    "            \"message\": f\"‚ùå {sample_name}: {e.stderr}\"\n",
    "        }\n",
    "\n",
    "\n",
    "def process_all_fragments(\n",
    "    input_dir: str,\n",
    "    output_dir: str,\n",
    "    max_workers: int = 8,\n",
    "    pattern: str = r\"\\.fragments\\.tsv\\.gz$\"\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Process all fragment files in a directory in parallel.\n",
    "    \"\"\"\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    \n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Find all fragment files\n",
    "    fragment_files = []\n",
    "    for entry in os.scandir(input_path):\n",
    "        if entry.is_file() and re.search(pattern, entry.name):\n",
    "            fragment_files.append(entry)\n",
    "    \n",
    "    if not fragment_files:\n",
    "        print(f\"‚ö†Ô∏è No fragment files found in {input_dir}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"üìÇ Found {len(fragment_files)} fragment files\")\n",
    "    print(f\"üìÅ Output directory: {output_dir}\")\n",
    "    print(f\"üë∑ Workers: {max_workers}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Build job list\n",
    "    jobs = [(entry.path, str(output_path / entry.name)) for entry in fragment_files]\n",
    "    \n",
    "    # Process in parallel\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(convert_fragments_to_cutsites, inp, out): inp \n",
    "            for inp, out in jobs\n",
    "        }\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            print(result[\"message\"])\n",
    "            results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Functions defined for fragment conversion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fcf151-7435-4f2e-ae0a-3dd20beb92ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Found 32 fragment files\n",
      "üìÅ Output directory: /cluster/project/treutlein/USERS/jjans/analysis/adult_intestine/peaks/fragment_files/Macaque\n",
      "üë∑ Workers: 8\n",
      "------------------------------------------------------------\n",
      "‚úÖ Adipocytes: 2.5 MB\n",
      "‚úÖ Enteric_neurons: 0.6 MB\n",
      "‚úÖ Enteric_glia: 8.8 MB\n",
      "‚úÖ ECs: 11.4 MB\n",
      "‚úÖ Specialized_Fibroblasts_KCNN3+: 11.3 MB\n",
      "‚úÖ ICCs: 3.1 MB\n",
      "‚úÖ EECs: 19.5 MB\n",
      "‚úÖ BEST4+_cells: 23.4 MB\n",
      "‚úÖ Monocytes: 8.5 MB\n",
      "‚úÖ Mesothelial_cells: 13.1 MB\n",
      "‚úÖ Myofibroblasts: 4.8 MB\n",
      "‚úÖ Paneth_cells: 5.0 MB\n",
      "‚úÖ Pericytes: 1.1 MB\n",
      "‚úÖ Crypt_Fibroblasts_WNT2B+: 52.4 MB\n",
      "‚úÖ Specialized_Fibroblasts_PCDH9+: 5.3 MB\n",
      "‚úÖ Specialized_Fibroblasts_RALYL+: 4.4 MB\n",
      "‚úÖ Colonocytes: 70.0 MB\n",
      "‚úÖ Plasma_B_cells: 24.0 MB\n",
      "‚úÖ Lymphatic_ECs: 67.7 MB\n",
      "‚úÖ Specialized_Fibroblasts_RSPO2_3+: 21.1 MB\n",
      "‚úÖ Enterocytes: 91.2 MB\n",
      "‚úÖ Specialized_Fibroblasts_VCAM1+: 8.5 MB\n",
      "‚úÖ Specialized_Fibroblasts_RSPO3+_only: 20.2 MB\n",
      "‚úÖ Specialized_Fibroblasts_SYNM+: 19.5 MB\n",
      "‚úÖ Tuft_cells: 7.5 MB\n",
      "‚úÖ Villus_Fibroblasts_WNT5B+: 8.7 MB\n",
      "‚úÖ Goblet_cells: 107.6 MB\n",
      "‚úÖ Macrophages: 110.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Run fragment to cut-site conversion\n",
    "cutsite_results = process_all_fragments(\n",
    "    input_dir=FRAGMENTS_INPUT_DIR,\n",
    "    output_dir=CUTSITES_OUTPUT_DIR,\n",
    "    max_workers=CUTSITE_WORKERS\n",
    ")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 1 SUMMARY - Fragment Conversion\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "successful = [r for r in cutsite_results if r[\"status\"] == \"success\"]\n",
    "failed = [r for r in cutsite_results if r[\"status\"] == \"error\"]\n",
    "total_size = sum(r[\"output_size_mb\"] for r in successful)\n",
    "\n",
    "print(f\"Total files processed: {len(cutsite_results)}\")\n",
    "print(f\"  ‚úÖ Successful: {len(successful)}\")\n",
    "print(f\"  ‚ùå Failed: {len(failed)}\")\n",
    "print(f\"  üíæ Total output size: {total_size:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a531474d-3dd9-4095-ad9c-600e7fd9c7d6",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 2: MACS3 Peak Calling\n",
    "\n",
    "Run MACS3 peak calling on the cut-site BED files.\n",
    "\n",
    "**Output files per sample:**\n",
    "- `*_peaks.narrowPeak`: BED6+4 format peak calls\n",
    "- `*_peaks.xls`: Spreadsheet with peak info  \n",
    "- `*_summits.bed`: Peak summit positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ab949-a1f5-46e4-ba1e-bf4a8b6a7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_macs3_command(sample_name, fragment_path, species, out_dir, macs3_path, params):\n",
    "    \"\"\"Build MACS3 command with configurable parameters.\"\"\"\n",
    "    \n",
    "    gsize = EFFECTIVE_GENOME_SIZES.get(species)\n",
    "    if gsize is None:\n",
    "        raise ValueError(f\"Unknown species: {species}. Available: {list(EFFECTIVE_GENOME_SIZES.keys())}\")\n",
    "    \n",
    "    cmd = [\n",
    "        macs3_path, \"callpeak\",\n",
    "        \"--treatment\", fragment_path,\n",
    "        \"--name\", sample_name,\n",
    "        \"--outdir\", out_dir,\n",
    "        \"--format\", params[\"format\"],\n",
    "        \"--gsize\", str(gsize),\n",
    "        \"--qvalue\", str(params[\"qvalue\"]),\n",
    "        \"--shift\", str(params[\"shift\"]),\n",
    "        \"--extsize\", str(params[\"extsize\"]),\n",
    "        \"--keep-dup\", str(params[\"keep_dup\"]),\n",
    "        \"--min-length\", str(params[\"min_length\"]),\n",
    "    ]\n",
    "    \n",
    "    if params.get(\"nomodel\"):\n",
    "        cmd.append(\"--nomodel\")\n",
    "    if params.get(\"call_summits\"):\n",
    "        cmd.append(\"--call-summits\")\n",
    "    if params.get(\"nolambda\"):\n",
    "        cmd.append(\"--nolambda\")\n",
    "    \n",
    "    return cmd\n",
    "\n",
    "\n",
    "def run_macs3_worker(job, species, out_dir, macs3_path, params):\n",
    "    \"\"\"Worker function for parallel MACS3 execution.\"\"\"\n",
    "    sample_name, fragment_path = job\n",
    "    \n",
    "    cmd = build_macs3_command(sample_name, fragment_path, species, out_dir, macs3_path, params)\n",
    "    \n",
    "    print(f\"üöÄ Starting: {sample_name}\")\n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "        \n",
    "        # Count peaks from the narrowPeak file\n",
    "        narrowpeak_file = os.path.join(out_dir, f\"{sample_name}_peaks.narrowPeak\")\n",
    "        peak_count = 0\n",
    "        if os.path.exists(narrowpeak_file):\n",
    "            with open(narrowpeak_file, 'r') as f:\n",
    "                peak_count = sum(1 for _ in f)\n",
    "        \n",
    "        return {\n",
    "            \"sample_name\": sample_name,\n",
    "            \"status\": \"success\",\n",
    "            \"peak_count\": peak_count,\n",
    "            \"message\": f\"‚úÖ Finished: {sample_name} ({peak_count:,} peaks)\"\n",
    "        }\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return {\n",
    "            \"sample_name\": sample_name,\n",
    "            \"status\": \"error\",\n",
    "            \"peak_count\": 0,\n",
    "            \"message\": f\"‚ùå Error in {sample_name}: {e.stderr}\"\n",
    "        }\n",
    "\n",
    "\n",
    "def run_peak_calling(\n",
    "    species,\n",
    "    frag_dir,\n",
    "    out_dir,\n",
    "    macs3_path=MACS3_PATH,\n",
    "    max_workers=15,\n",
    "    params=None,\n",
    "    **param_overrides\n",
    "):\n",
    "    \"\"\"\n",
    "    Run MACS3 peak calling in parallel for all fragment files.\n",
    "    \n",
    "    Args:\n",
    "        species: Species name (must be in EFFECTIVE_GENOME_SIZES)\n",
    "        frag_dir: Directory with cut-site fragment files\n",
    "        out_dir: Output directory for peaks\n",
    "        macs3_path: Path to macs3 executable\n",
    "        max_workers: Number of parallel workers/cores (default: 15)\n",
    "        params: Full parameter dict (if None, uses MACS3_PARAMS)\n",
    "        **param_overrides: Individual parameters to override\n",
    "    \n",
    "    Returns:\n",
    "        List of result dicts containing sample info and peak counts\n",
    "    \"\"\"\n",
    "    # Build final parameters\n",
    "    final_params = (params if params is not None else MACS3_PARAMS).copy()\n",
    "    final_params.update(param_overrides)\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all fragment files\n",
    "    fragment_files = [f for f in os.listdir(frag_dir) if f.endswith(\".fragments.tsv.gz\")]\n",
    "    \n",
    "    if not fragment_files:\n",
    "        print(f\"‚ö†Ô∏è No fragment files found in {frag_dir}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"üìÇ Found {len(fragment_files)} fragment files for {species}\")\n",
    "    print(f\"üìÅ Output directory: {out_dir}\")\n",
    "    print(f\"üß¨ Genome size: {EFFECTIVE_GENOME_SIZES[species]:,}\")\n",
    "    print(f\"‚öôÔ∏è Parameters: qvalue={final_params['qvalue']}, shift={final_params['shift']}, extsize={final_params['extsize']}, min_length={final_params['min_length']}\")\n",
    "    print(f\"üë∑ Workers: {max_workers}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Save parameters to file\n",
    "    params_file = os.path.join(out_dir, \"macs3_parameters.json\")\n",
    "    params_to_save = {\n",
    "        \"species\": species,\n",
    "        \"genome_size\": EFFECTIVE_GENOME_SIZES[species],\n",
    "        \"macs3_path\": macs3_path,\n",
    "        \"max_workers\": max_workers,\n",
    "        \"frag_dir\": frag_dir,\n",
    "        \"out_dir\": out_dir,\n",
    "        \"run_date\": datetime.now().isoformat(),\n",
    "        \"macs3_params\": final_params\n",
    "    }\n",
    "    with open(params_file, 'w') as f:\n",
    "        json.dump(params_to_save, f, indent=2)\n",
    "    print(f\"üíæ Parameters saved to: {params_file}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Create jobs list\n",
    "    jobs = [(f.split('.')[0], os.path.join(frag_dir, f)) for f in fragment_files]\n",
    "    \n",
    "    # Create worker with fixed arguments\n",
    "    worker = partial(\n",
    "        run_macs3_worker,\n",
    "        species=species,\n",
    "        out_dir=out_dir,\n",
    "        macs3_path=macs3_path,\n",
    "        params=final_params\n",
    "    )\n",
    "    \n",
    "    # Run in parallel\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(worker, jobs))\n",
    "    \n",
    "    # Generate peak count report\n",
    "    report_file = os.path.join(out_dir, \"peak_counts_report.tsv\")\n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(\"cell_type\\tpeak_count\\tstatus\\n\")\n",
    "        for result in results:\n",
    "            f.write(f\"{result['sample_name']}\\t{result['peak_count']}\\t{result['status']}\\n\")\n",
    "    print(f\"\\nüìä Peak count report saved to: {report_file}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Functions defined for MACS3 peak calling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa934d7-bc10-4fb1-9983-859ca0695dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MACS3 peak calling\n",
    "peak_results = run_peak_calling(\n",
    "    species=SPECIES,\n",
    "    frag_dir=CUTSITES_OUTPUT_DIR,\n",
    "    out_dir=PEAKS_OUTPUT_DIR,\n",
    "    macs3_path=MACS3_PATH,\n",
    "    max_workers=MACS3_WORKERS,\n",
    "    # Parameter overrides (uncomment to modify):\n",
    "    # qvalue=0.05,\n",
    "    # min_length=150,\n",
    ")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 2 SUMMARY - Peak Calling Results\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_peaks = 0\n",
    "successful = 0\n",
    "failed = 0\n",
    "\n",
    "for result in peak_results:\n",
    "    print(result[\"message\"])\n",
    "    if result[\"status\"] == \"success\":\n",
    "        successful += 1\n",
    "        total_peaks += result[\"peak_count\"]\n",
    "    else:\n",
    "        failed += 1\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(f\"Total samples processed: {len(peak_results)}\")\n",
    "print(f\"  ‚úÖ Successful: {successful}\")\n",
    "print(f\"  ‚ùå Failed: {failed}\")\n",
    "print(f\"  üìä Total peaks called: {total_peaks:,}\")\n",
    "print(f\"\\nOutput saved to: {PEAKS_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7c5454-a6a0-4bad-b9e8-e0cda988e98d",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary Report\n",
    "\n",
    "Display final statistics and output locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907f6f01-e75d-419d-b8ef-01435ccb0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and display peak count report\n",
    "report_path = os.path.join(PEAKS_OUTPUT_DIR, \"peak_counts_report.tsv\")\n",
    "\n",
    "if os.path.exists(report_path):\n",
    "    df = pd.read_csv(report_path, sep='\\t')\n",
    "    df_sorted = df.sort_values('peak_count', ascending=False)\n",
    "    \n",
    "    print(\"Peak counts per cell type (sorted by count):\")\n",
    "    print(\"=\" * 50)\n",
    "    display(df_sorted)\n",
    "    \n",
    "    print(f\"\\nTotal peaks: {df['peak_count'].sum():,}\")\n",
    "    print(f\"Mean peaks per cell type: {df['peak_count'].mean():,.0f}\")\n",
    "    print(f\"Median peaks per cell type: {df['peak_count'].median():,.0f}\")\n",
    "else:\n",
    "    print(\"Peak count report not found. Run Step 2 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0563a-53aa-4e31-becb-2f49bcd5fe94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6f55e-8436-46bb-87f1-7387d3700328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b6de6-b36c-4401-b176-5ad8f8b12ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scenicplus",
   "language": "python",
   "name": "scenicplus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
